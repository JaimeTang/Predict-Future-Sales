{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入Python包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlxtend\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import warnings\n",
    "import gc\n",
    "import sys\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据并预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sales_train_v2.csv')\n",
    "shops = pd.read_csv('shops.csv')\n",
    "items = pd.read_csv('items.csv')\n",
    "cats = pd.read_csv('item_categories.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train.date,format=\"%d.%m.%Y\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异常值检测,绘制箱型图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['shop_id','item_id','item_price','item_cnt_day']].plot(kind='box',subplots=True,layout=(2,2),sharex=False,sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取需要剔除的偏离值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['item_price']<100000]\n",
    "train = train[train['item_cnt_day']<1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "对销量和价格小于0的值进行替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.item_price<0, 'item_price'] = 0\n",
    "train.loc[train.item_cnt_day<0,'item_cnt_day'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shops/Items/Cats的特征预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shops特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x:x[0])\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops = shops[['shop_id','city_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cats的特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats['type'] = cats['item_category_name'].str.split('-').map(lambda x:x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "cats['subtype'] = cats['item_category_name'].str.split('-').map(lambda x:x[1].strip() if len(x)>1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code','subtype_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Items的特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(['item_name'],axis=1,inplace=True)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成月销量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "matrix = []\n",
    "col = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = train[train['date_block_num']==i]\n",
    "    matrix.append(np.array(list(product([i],sales['shop_id'].unique(),sales['item_id'].unique())),dtype='int16'))\n",
    "\n",
    "matrix = pd.DataFrame(np.vstack(matrix),columns=col)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix.sort_values(col,inplace=True)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['revenue'] = train['item_price']*train['item_cnt_day']\n",
    "group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day':'sum'})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "matrix = pd.merge(matrix,group,on=col,how='left')\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].fillna(0).clip(0.0,20).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "\n",
    "matrix = pd.concat([matrix,test],keys=col,ignore_index=True).fillna(0)\n",
    "matrix['ID'] = matrix['ID'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shops/Items/Cats特征连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\n",
    "matrix = pd.merge(matrix, items, on=['item_id'], how='left')\n",
    "matrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n",
    "\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成滞后特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left').fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成均值特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\n",
    "matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\n",
    "matrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\n",
    "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_shop_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_cat_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\n",
    "matrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_cat_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\n",
    "matrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_type_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\n",
    "matrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\n",
    "matrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\n",
    "matrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\n",
    "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\n",
    "matrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\n",
    "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_type_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\n",
    "matrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\n",
    "matrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_subtype_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "matrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 趋势特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['item_id'], how='left')\n",
    "matrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "group = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "lags = [1,2,3,4,5,6]\n",
    "matrix = lag_feature(matrix, lags, 'date_item_avg_item_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lags:\n",
    "    matrix['delta_price_lag_'+str(i)] = \\\n",
    "        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "matrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "matrix['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "fetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\n",
    "group.columns = ['date_shop_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n",
    "\n",
    "group = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\n",
    "group.columns = ['shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['shop_id'], how='left')\n",
    "matrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n",
    "\n",
    "matrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
    "matrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'delta_revenue')\n",
    "\n",
    "matrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特定特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['month'] = matrix['date_block_num'] % 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix['days'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_shop_last_sale'] = -1\n",
    "matrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_last_sale'] = -1\n",
    "matrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最终的预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取13年以后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix[matrix['date_block_num'] > 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)         \n",
    "    return df\n",
    "\n",
    "matrix = fill_na(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.to_pickle('data.pkl')\n",
    "del matrix\n",
    "del cache\n",
    "del group\n",
    "del items\n",
    "del shops\n",
    "del cats\n",
    "del train\n",
    "# leave test for submission\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建立和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data.pkl')\n",
    "data = data.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\n",
    "    'date_block_num',\n",
    "    'shop_id',\n",
    "    'item_id',\n",
    "    'item_cnt_month',\n",
    "    'city_code',\n",
    "    'item_category_id',\n",
    "    'type_code',\n",
    "    'item_cnt_month_lag_1',\n",
    "    'item_cnt_month_lag_2',\n",
    "    'item_cnt_month_lag_3',\n",
    "    'item_cnt_month_lag_5',\n",
    "    'item_cnt_month_lag_12',\n",
    "    'date_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_2',\n",
    "    'date_item_avg_item_cnt_lag_3',\n",
    "    'date_item_avg_item_cnt_lag_6',\n",
    "    'date_item_avg_item_cnt_lag_12',\n",
    "    'date_shop_avg_item_cnt_lag_1',\n",
    "    'date_shop_avg_item_cnt_lag_2',\n",
    "    'date_shop_avg_item_cnt_lag_3',\n",
    "    'date_shop_avg_item_cnt_lag_6',\n",
    "    'date_shop_avg_item_cnt_lag_12',\n",
    "    'date_cat_avg_item_cnt_lag_1',\n",
    "    'date_shop_cat_avg_item_cnt_lag_1',\n",
    "    'date_shop_type_avg_item_cnt_lag_1',\n",
    "    'date_shop_subtype_avg_item_cnt_lag_1',\n",
    "    'date_city_avg_item_cnt_lag_1',\n",
    "    'date_item_city_avg_item_cnt_lag_1',\n",
    "    'date_type_avg_item_cnt_lag_1',\n",
    "    'delta_price_lag',\n",
    "    'month',\n",
    "    'days',\n",
    "    'item_shop_last_sale',\n",
    "    'item_last_sale',    \n",
    "    'item_shop_first_sale',\n",
    "    'item_first_sale',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(seed=42,\n",
    "                   #nthread=-1,\n",
    "                   learning_rate=0.05,\n",
    "                   max_depth=8,\n",
    "                   min_child_weight=100,\n",
    "                   n_estimators =1000,\n",
    "                   colsample_bytree=0.4,\n",
    "                   subsample=0.75,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5,random_state=42)\n",
    "model = GridSearchCV(xgb,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=kfold,\n",
    "                     param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:22:52] Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\tvalidation_0-rmse:1.18208\tvalidation_1-rmse:1.14307\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-rmse:1.1618\tvalidation_1-rmse:1.12588\n",
      "[2]\tvalidation_0-rmse:1.13759\tvalidation_1-rmse:1.1067\n",
      "[3]\tvalidation_0-rmse:1.11653\tvalidation_1-rmse:1.09148\n",
      "[4]\tvalidation_0-rmse:1.09823\tvalidation_1-rmse:1.07828\n",
      "[5]\tvalidation_0-rmse:1.08158\tvalidation_1-rmse:1.06688\n",
      "[6]\tvalidation_0-rmse:1.06489\tvalidation_1-rmse:1.0552\n",
      "[7]\tvalidation_0-rmse:1.0492\tvalidation_1-rmse:1.04365\n",
      "[8]\tvalidation_0-rmse:1.03521\tvalidation_1-rmse:1.03261\n",
      "[9]\tvalidation_0-rmse:1.02191\tvalidation_1-rmse:1.02328\n",
      "[10]\tvalidation_0-rmse:1.00885\tvalidation_1-rmse:1.01382\n",
      "[11]\tvalidation_0-rmse:0.999226\tvalidation_1-rmse:1.00727\n",
      "[12]\tvalidation_0-rmse:0.988663\tvalidation_1-rmse:1.00022\n",
      "[13]\tvalidation_0-rmse:0.979997\tvalidation_1-rmse:0.994136\n",
      "[14]\tvalidation_0-rmse:0.971749\tvalidation_1-rmse:0.988115\n",
      "[15]\tvalidation_0-rmse:0.963135\tvalidation_1-rmse:0.982571\n",
      "[16]\tvalidation_0-rmse:0.955402\tvalidation_1-rmse:0.975803\n",
      "[17]\tvalidation_0-rmse:0.948135\tvalidation_1-rmse:0.971406\n",
      "[18]\tvalidation_0-rmse:0.941519\tvalidation_1-rmse:0.967357\n",
      "[19]\tvalidation_0-rmse:0.935074\tvalidation_1-rmse:0.963352\n",
      "[20]\tvalidation_0-rmse:0.928927\tvalidation_1-rmse:0.959418\n",
      "[21]\tvalidation_0-rmse:0.92337\tvalidation_1-rmse:0.956014\n",
      "[22]\tvalidation_0-rmse:0.918205\tvalidation_1-rmse:0.952779\n",
      "[23]\tvalidation_0-rmse:0.91228\tvalidation_1-rmse:0.948715\n",
      "[24]\tvalidation_0-rmse:0.90766\tvalidation_1-rmse:0.94617\n",
      "[25]\tvalidation_0-rmse:0.90514\tvalidation_1-rmse:0.94456\n",
      "[26]\tvalidation_0-rmse:0.901073\tvalidation_1-rmse:0.942083\n",
      "[27]\tvalidation_0-rmse:0.897837\tvalidation_1-rmse:0.940438\n",
      "[28]\tvalidation_0-rmse:0.894637\tvalidation_1-rmse:0.937993\n",
      "[29]\tvalidation_0-rmse:0.890281\tvalidation_1-rmse:0.934626\n",
      "[30]\tvalidation_0-rmse:0.886289\tvalidation_1-rmse:0.932398\n",
      "[31]\tvalidation_0-rmse:0.884149\tvalidation_1-rmse:0.931219\n",
      "[32]\tvalidation_0-rmse:0.881092\tvalidation_1-rmse:0.92986\n",
      "[33]\tvalidation_0-rmse:0.8787\tvalidation_1-rmse:0.928719\n",
      "[34]\tvalidation_0-rmse:0.875622\tvalidation_1-rmse:0.926215\n",
      "[35]\tvalidation_0-rmse:0.873605\tvalidation_1-rmse:0.925399\n",
      "[36]\tvalidation_0-rmse:0.871665\tvalidation_1-rmse:0.924608\n",
      "[37]\tvalidation_0-rmse:0.869191\tvalidation_1-rmse:0.922732\n",
      "[38]\tvalidation_0-rmse:0.867304\tvalidation_1-rmse:0.921729\n",
      "[39]\tvalidation_0-rmse:0.865407\tvalidation_1-rmse:0.921004\n",
      "[40]\tvalidation_0-rmse:0.862762\tvalidation_1-rmse:0.920279\n",
      "[41]\tvalidation_0-rmse:0.859984\tvalidation_1-rmse:0.918771\n",
      "[42]\tvalidation_0-rmse:0.857361\tvalidation_1-rmse:0.917453\n",
      "[43]\tvalidation_0-rmse:0.855669\tvalidation_1-rmse:0.917084\n",
      "[44]\tvalidation_0-rmse:0.85344\tvalidation_1-rmse:0.91572\n",
      "[45]\tvalidation_0-rmse:0.851525\tvalidation_1-rmse:0.914855\n",
      "[46]\tvalidation_0-rmse:0.850236\tvalidation_1-rmse:0.914163\n",
      "[47]\tvalidation_0-rmse:0.849401\tvalidation_1-rmse:0.914\n",
      "[48]\tvalidation_0-rmse:0.848357\tvalidation_1-rmse:0.91366\n",
      "[49]\tvalidation_0-rmse:0.847593\tvalidation_1-rmse:0.913282\n",
      "[50]\tvalidation_0-rmse:0.846387\tvalidation_1-rmse:0.912894\n",
      "[51]\tvalidation_0-rmse:0.844959\tvalidation_1-rmse:0.912403\n",
      "[52]\tvalidation_0-rmse:0.844381\tvalidation_1-rmse:0.912312\n",
      "[53]\tvalidation_0-rmse:0.843312\tvalidation_1-rmse:0.911705\n",
      "[54]\tvalidation_0-rmse:0.842188\tvalidation_1-rmse:0.911422\n",
      "[55]\tvalidation_0-rmse:0.840981\tvalidation_1-rmse:0.91052\n",
      "[56]\tvalidation_0-rmse:0.839536\tvalidation_1-rmse:0.910255\n",
      "[57]\tvalidation_0-rmse:0.838648\tvalidation_1-rmse:0.910463\n",
      "[58]\tvalidation_0-rmse:0.838231\tvalidation_1-rmse:0.910305\n",
      "[59]\tvalidation_0-rmse:0.837093\tvalidation_1-rmse:0.909899\n",
      "[60]\tvalidation_0-rmse:0.836267\tvalidation_1-rmse:0.909761\n",
      "[61]\tvalidation_0-rmse:0.835655\tvalidation_1-rmse:0.909608\n",
      "[62]\tvalidation_0-rmse:0.835082\tvalidation_1-rmse:0.909425\n",
      "[63]\tvalidation_0-rmse:0.834185\tvalidation_1-rmse:0.908991\n",
      "[64]\tvalidation_0-rmse:0.833426\tvalidation_1-rmse:0.908782\n",
      "[65]\tvalidation_0-rmse:0.832138\tvalidation_1-rmse:0.908017\n",
      "[66]\tvalidation_0-rmse:0.831557\tvalidation_1-rmse:0.907743\n",
      "[67]\tvalidation_0-rmse:0.831064\tvalidation_1-rmse:0.907766\n",
      "[68]\tvalidation_0-rmse:0.830806\tvalidation_1-rmse:0.907609\n",
      "[69]\tvalidation_0-rmse:0.830112\tvalidation_1-rmse:0.907675\n",
      "[70]\tvalidation_0-rmse:0.82949\tvalidation_1-rmse:0.907639\n",
      "[71]\tvalidation_0-rmse:0.828574\tvalidation_1-rmse:0.907858\n",
      "[72]\tvalidation_0-rmse:0.827835\tvalidation_1-rmse:0.907955\n",
      "[73]\tvalidation_0-rmse:0.827253\tvalidation_1-rmse:0.907711\n",
      "[74]\tvalidation_0-rmse:0.826836\tvalidation_1-rmse:0.907432\n",
      "[75]\tvalidation_0-rmse:0.825939\tvalidation_1-rmse:0.906947\n",
      "[76]\tvalidation_0-rmse:0.825628\tvalidation_1-rmse:0.906851\n",
      "[77]\tvalidation_0-rmse:0.825274\tvalidation_1-rmse:0.906803\n",
      "[78]\tvalidation_0-rmse:0.824795\tvalidation_1-rmse:0.906668\n",
      "[79]\tvalidation_0-rmse:0.824114\tvalidation_1-rmse:0.906612\n",
      "[80]\tvalidation_0-rmse:0.823253\tvalidation_1-rmse:0.906113\n",
      "[81]\tvalidation_0-rmse:0.822868\tvalidation_1-rmse:0.906359\n",
      "[82]\tvalidation_0-rmse:0.822483\tvalidation_1-rmse:0.906392\n",
      "[83]\tvalidation_0-rmse:0.82151\tvalidation_1-rmse:0.905691\n",
      "[84]\tvalidation_0-rmse:0.821243\tvalidation_1-rmse:0.905688\n",
      "[85]\tvalidation_0-rmse:0.820754\tvalidation_1-rmse:0.905638\n",
      "[86]\tvalidation_0-rmse:0.820376\tvalidation_1-rmse:0.905808\n",
      "[87]\tvalidation_0-rmse:0.820006\tvalidation_1-rmse:0.905613\n",
      "[88]\tvalidation_0-rmse:0.81975\tvalidation_1-rmse:0.905839\n",
      "[89]\tvalidation_0-rmse:0.818586\tvalidation_1-rmse:0.905106\n",
      "[90]\tvalidation_0-rmse:0.817934\tvalidation_1-rmse:0.904614\n",
      "[91]\tvalidation_0-rmse:0.8174\tvalidation_1-rmse:0.904982\n",
      "[92]\tvalidation_0-rmse:0.817183\tvalidation_1-rmse:0.904874\n",
      "[93]\tvalidation_0-rmse:0.816815\tvalidation_1-rmse:0.904728\n",
      "[94]\tvalidation_0-rmse:0.816333\tvalidation_1-rmse:0.904853\n",
      "[95]\tvalidation_0-rmse:0.81595\tvalidation_1-rmse:0.90492\n",
      "[96]\tvalidation_0-rmse:0.815617\tvalidation_1-rmse:0.905102\n",
      "[97]\tvalidation_0-rmse:0.814934\tvalidation_1-rmse:0.905202\n",
      "[98]\tvalidation_0-rmse:0.814747\tvalidation_1-rmse:0.905177\n",
      "[99]\tvalidation_0-rmse:0.814336\tvalidation_1-rmse:0.904971\n",
      "[100]\tvalidation_0-rmse:0.814091\tvalidation_1-rmse:0.905334\n",
      "Stopping. Best iteration:\n",
      "[90]\tvalidation_0-rmse:0.817934\tvalidation_1-rmse:0.904614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.4, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=100, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train,y_train,\n",
    "          eval_metric='rmse',\n",
    "          eval_set=[(X_train,y_train),(X_valid,y_valid)],\n",
    "          early_stopping_rounds=10,\n",
    "          verbose=1\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.619383"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09757024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": test.index, \n",
    "    \"item_cnt_month\": y_test\n",
    "})\n",
    "submission.to_csv('xgb_submission_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model,open('model/model_6.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
